{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c212206a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "from glob import glob\n",
    "import torchvision.transforms as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.notebook import tqdm, trange\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import WeightedRandomSampler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, precision_recall_curve, average_precision_score\n",
    "from typing import Tuple, Dict, List\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89cc4baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "learning_rate = 1e-4\n",
    "batch_size = 16\n",
    "num_workers = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f682e093",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_classes(directory: str) -> Tuple[List[str], Dict[str, int]]:\n",
    "    \n",
    "    classes = sorted(entry.name for entry in os.scandir(directory) if entry.is_dir())\n",
    "    \n",
    "    if not classes:\n",
    "        \n",
    "        raise FileNotFoundError(f\"Couldn't find any classes in {directory}.\")\n",
    "    \n",
    "    class_to_idx = {cls_name: i for i, cls_name in enumerate(classes)}\n",
    "    \n",
    "    return classes, class_to_idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2ef971b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageFolderCustom(Dataset):\n",
    "\n",
    "    def __init__(self, targ_dir: str, transform=None) -> None:\n",
    "        \n",
    "        self.paths = list(pathlib.Path(targ_dir).glob(\"*/*.npy\"))\n",
    "\n",
    "        self.transform = transform\n",
    "\n",
    "        self.classes, self.class_to_idx = find_classes(targ_dir)\n",
    "        \n",
    "\n",
    "    def load_image(self, index: int) -> Image.Image:\n",
    "\n",
    "        image_path = self.paths[index]\n",
    "        \n",
    "        return np.load(image_path) \n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "\n",
    "        return len(self.paths)\n",
    "    \n",
    "    def __getitem__(self, index: int) -> Tuple[torch.Tensor, int]:\n",
    "\n",
    "        img = self.load_image(index)\n",
    "        img = np.expand_dims(img, axis = 0)\n",
    "        class_name  = self.paths[index].parent.name \n",
    "        class_idx = self.class_to_idx[class_name]\n",
    "\n",
    "        if self.transform:\n",
    "            \n",
    "            return self.transform(img), class_idx \n",
    "        \n",
    "        else:\n",
    "            \n",
    "            return img, class_idx \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e14dfb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_dir = 'E:/Tanvir Mehedi/Nodule_Classification/Data/train/'\n",
    "\n",
    "val_img_dir = 'E:/Tanvir Mehedi/Nodule_Classification/Data/validation/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3970916c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_dir = 'E:/Tanvir Mehedi/Nodule_Classification/Saved_models/Base_NN_model/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54de1a5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['neg_cube', 'pos_cube']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_dir = train_img_dir\n",
    "\n",
    "no_of_subdirectories = len(glob(img_dir + '*'))\n",
    "\n",
    "subdirectories = [glob(img_dir + '*')[i].split('\\\\')[-1] for i in range(no_of_subdirectories) ]\n",
    "subdirectories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2789d089",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3.797184767213588e-06, 7.23589001447178e-05]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_of_subdirectories = len(glob(img_dir + '*'))\n",
    "subdirectories = [glob(img_dir + '*')[i].split('\\\\')[-1] for i in range(no_of_subdirectories) ]\n",
    "\n",
    "class_weights = []\n",
    "\n",
    "for subdir in subdirectories:\n",
    "    files = os.listdir(os.path.join(img_dir, subdir))\n",
    "    class_weights.append(1 / len(files))\n",
    "    \n",
    "class_weights  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3db2849",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fa972a2c80740e18a949df7736758af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_ds = ImageFolderCustom(\n",
    "#         targ_dir = train_img_dir,\n",
    "        targ_dir = img_dir,\n",
    "        transform = None,\n",
    "    )\n",
    "\n",
    "sample_weights = [0] * len(train_ds)\n",
    "\n",
    "for idx, (data, label) in tqdm(enumerate(train_ds)):\n",
    "    \n",
    "    class_weight = class_weights[label]\n",
    "    sample_weights[idx] = class_weight\n",
    "\n",
    "sampler = WeightedRandomSampler(sample_weights, num_samples=len(sample_weights), replacement=True)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "        train_ds,\n",
    "        batch_size = batch_size,\n",
    "        sampler = sampler,\n",
    "        num_workers = num_workers,\n",
    "        drop_last = True,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952e648f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_ds = ImageFolderCustom(\n",
    "#         targ_dir = train_img_dir,\n",
    "#         transform = None,\n",
    "#     )\n",
    "\n",
    "# train_loader = DataLoader(\n",
    "#         train_ds,\n",
    "#         batch_size = batch_size,\n",
    "#         num_workers = num_workers,\n",
    "#         shuffle = True,\n",
    "#         drop_last = True,\n",
    "#     )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "afd44403",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ds = ImageFolderCustom(\n",
    "        targ_dir = val_img_dir,\n",
    "        transform = None,\n",
    "    )\n",
    "\n",
    "val_loader = DataLoader(\n",
    "        val_ds,\n",
    "        batch_size = batch_size,\n",
    "        num_workers = num_workers,\n",
    "        shuffle = False,\n",
    "        drop_last = True,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f9744549",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_paper import Base_NN_Model\n",
    "\n",
    "model =  Base_NN_Model()\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1b4d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ResNet3D_model import ResNet3D\n",
    "\n",
    "# model =  ResNet3D()\n",
    "# model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b560a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the class frequencies\n",
    "\n",
    "# no_of_pos_files = 18657\n",
    "# no_of_neg_files = 263353\n",
    "\n",
    "# positive_frequency = no_of_pos_files/(no_of_pos_files + no_of_neg_files)\n",
    "# negative_frequency = 1 - positive_frequency\n",
    "\n",
    "# # Assign weights to each class proportional to the inverse of its frequency\n",
    "\n",
    "# positive_weight = 1 / positive_frequency\n",
    "# negative_weight = 1 / negative_frequency\n",
    "\n",
    "# # Normalize the weights so that they sum up to 1\n",
    "\n",
    "# total_weight = positive_weight + negative_weight\n",
    "# positive_weight /= total_weight\n",
    "# negative_weight /= total_weight\n",
    "\n",
    "# # Define the class weights tensor\n",
    "\n",
    "# class_weights = torch.FloatTensor([negative_weight, positive_weight]).to(device)\n",
    "\n",
    "# class_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "599f478d",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(params = model.parameters(), lr = learning_rate) \n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate, momentum = 0.9)\n",
    "\n",
    "loss_criterion = torch.nn.CrossEntropyLoss()\n",
    "# loss_criterion = torch.nn.CrossEntropyLoss(weight = class_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "babf2df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {\"train_loss\": [],\n",
    "        \"train_accuracy\": [],\n",
    "        \"validation_loss\": [],\n",
    "        \"validation_accuracy\": []\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8ac8fbdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17323"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7a758d73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e463ed228b14ac8ac6fb1b872b050f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(138853, device='cuda:0') tensor(138315, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1):\n",
    "    pos = 0\n",
    "    neg = 0\n",
    "    \n",
    "    for itera_no, data in tqdm(enumerate(train_loader)):\n",
    "        \n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "#         print(labels)\n",
    "        \n",
    "        neg += torch.sum(labels == 0)\n",
    "        pos += torch.sum(labels == 1)\n",
    "        \n",
    "print(pos,neg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d46325c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = 'E:/Tanvir Mehedi/Nodule_Classification/Saved_models/Base_NN_model/'\n",
    "\n",
    "def save_checkpoint(state, filename = root_dir + 'val_checkpoint_Base_NN_model.pt.tar'):\n",
    "    \n",
    "    print('=> Saving Checkpoint')\n",
    "    torch.save(state, filename)\n",
    "    \n",
    "def save_sensitive_checkpoint(state, filename = root_dir + 'val_sensitive_Base_NN_model_checkpoint.pt.tar'):\n",
    "    \n",
    "    print('=> Saving Checkpoint')\n",
    "    torch.save(state, filename)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cecd2ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "def auc_roc_calc(all_labels, pos_preds):\n",
    "    \n",
    "    all_labels_on_cpu = []\n",
    "\n",
    "    for tensor in all_labels:\n",
    "        tensor_on_cpu = tensor.cpu().numpy()\n",
    "        all_labels_on_cpu.append(tensor_on_cpu)\n",
    "\n",
    "    pos_preds_on_cpu = []\n",
    "\n",
    "    for tensor in pos_preds:\n",
    "        tensor_on_cpu = tensor.cpu().numpy()\n",
    "        pos_preds_on_cpu.append(tensor_on_cpu)\n",
    "\n",
    "    auc_roc = roc_auc_score(all_labels_on_cpu, pos_preds_on_cpu)\n",
    "    \n",
    "    return all_labels_on_cpu, pos_preds_on_cpu, auc_roc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6a0eacf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_epochs = 50\n",
    "\n",
    "best_score = 0\n",
    "best_sen_score = 0\n",
    "best_auc_roc = 0\n",
    "all_auc_roc = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e9e22134",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fa8a5f7156246ac86148b8f3cc47695",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch: 1:   0%|          | 0/17323 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 ) Training Loss :  0.7507112640497186\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccc01565ab034555af38adbdef9afead",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [3791, 60656]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11696/4246241965.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     79\u001b[0m     \u001b[0mF1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0msensitivity\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mprecision\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msensitivity\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mprecision\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 81\u001b[1;33m     \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mauc_roc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mauc_roc_calc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos_preds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     82\u001b[0m     \u001b[0mall_auc_roc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mauc_roc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11696/2300626655.py\u001b[0m in \u001b[0;36mauc_roc_calc\u001b[1;34m(all_labels, pos_preds)\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mpos_preds_on_cpu\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor_on_cpu\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0mauc_roc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_labels_on_cpu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos_preds_on_cpu\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mall_labels_on_cpu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos_preds_on_cpu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mauc_roc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\bme_ct\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\u001b[0m in \u001b[0;36mroc_auc_score\u001b[1;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001b[0m\n\u001b[0;32m    573\u001b[0m         )\n\u001b[0;32m    574\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# multilabel-indicator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 575\u001b[1;33m         return _average_binary_score(\n\u001b[0m\u001b[0;32m    576\u001b[0m             \u001b[0mpartial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_binary_roc_auc_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_fpr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_fpr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    577\u001b[0m             \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\bme_ct\\lib\\site-packages\\sklearn\\metrics\\_base.py\u001b[0m in \u001b[0;36m_average_binary_score\u001b[1;34m(binary_metric, y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[0;32m     75\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mbinary_metric\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     78\u001b[0m     \u001b[0my_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m     \u001b[0my_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_score\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\bme_ct\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    329\u001b[0m     \u001b[0muniques\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 331\u001b[1;33m         raise ValueError(\n\u001b[0m\u001b[0;32m    332\u001b[0m             \u001b[1;34m\"Found input variables with inconsistent numbers of samples: %r\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    333\u001b[0m             \u001b[1;33m%\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlengths\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [3791, 60656]"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, total_epochs+1):\n",
    "    \n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    train_loss = 0\n",
    "    CM = 0\n",
    "    \n",
    "    pbar = tqdm(train_loader, desc='Epoch: {}'.format(epoch))\n",
    "    \n",
    "    for itera_no, data in enumerate(pbar):\n",
    "        \n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        out = model(images)\n",
    "        \n",
    "        \n",
    "        loss = loss_criterion(out, labels)\n",
    "    \n",
    "        train_loss += loss.item()\n",
    "        loss.backward()\n",
    "        \n",
    "#         torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm =2.0, norm_type=2.0)\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        pred_class = torch.argmax(torch.nn.functional.softmax(out, dim = 1), dim = 1)\n",
    "        \n",
    "          \n",
    "    train_loss = train_loss / len(train_loader)\n",
    "    results['train_loss'].append(train_loss)\n",
    "  \n",
    "    print(epoch,\") Training Loss : \", train_loss)\n",
    "    \n",
    "    model.eval() \n",
    "    \n",
    "    val_loss =  0\n",
    "    val_acc = 0\n",
    "    \n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "    pos_preds = []\n",
    "\n",
    "    with torch.inference_mode():\n",
    "\n",
    "        for itera_no, val_data in tqdm(enumerate(val_loader)):\n",
    "\n",
    "            val_images, val_labels = val_data\n",
    "            val_images, val_labels = val_images.to(device), val_labels.to(device)\n",
    "            all_labels.append(val_labels)\n",
    "\n",
    "            val_pred_logits = model(val_images)\n",
    "\n",
    "            v_loss = loss_criterion(val_pred_logits, val_labels)\n",
    "            val_loss += v_loss.item()\n",
    "            \n",
    "            for pos_logit in val_pred_logits:\n",
    "    \n",
    "                pos_preds.append(torch.sigmoid(pos_logit[1]))\n",
    "        \n",
    "            all_preds.append(torch.sigmoid(val_pred_logits))\n",
    "        \n",
    "            val_class =  torch.argmax(torch.nn.functional.softmax(val_pred_logits, dim = 1), dim = 1)          \n",
    "            \n",
    "            CM+=confusion_matrix(val_labels.cpu(), val_class.cpu(), labels = [0,1]) \n",
    "\n",
    "\n",
    "    val_loss = val_loss / len(val_loader)\n",
    "    results['validation_loss'].append(val_loss)\n",
    "    \n",
    "    tn=CM[0][0]\n",
    "    tp=CM[1][1]\n",
    "    fp=CM[0][1]\n",
    "    fn=CM[1][0]\n",
    "    acc=np.sum(np.diag(CM)/np.sum(CM))\n",
    "    sensitivity=tp/(tp+fn)\n",
    "    precision=tp/(tp+fp)\n",
    "    F1 = ((2*sensitivity*precision)/(sensitivity+precision))*100\n",
    "    \n",
    "    _, _, auc_roc = auc_roc_calc(all_labels, pos_preds)\n",
    "    all_auc_roc.append(auc_roc)\n",
    "    \n",
    "    print('\\nValidation Accuracy(mean): %f %%' % (100 * acc))\n",
    "    print()\n",
    "    print('Confusion Matirx : ')\n",
    "    print(CM)\n",
    "    print('- Sensitivity : ',(tp/(tp+fn))*100)\n",
    "    print('- Specificity : ',(tn/(tn+fp))*100)\n",
    "    print('- Precision: ',(tp/(tp+fp))*100)\n",
    "    print('- NPV: ',(tn/(tn+fn))*100)\n",
    "    print('- F1 : ',F1)\n",
    "    print('AUC', auc_roc)\n",
    "    \n",
    "    print(epoch,\") Validation Loss : \", val_loss)\n",
    "\n",
    "    if F1>best_score:\n",
    "        \n",
    "        best_score = F1\n",
    "        \n",
    "        val_checkpoint = {'model_state' : model.state_dict(), 'optimizer_state' : optimizer.state_dict(), \n",
    "                               'F1_Score' : F1, 'val_sensitivity_score' : sensitivity, 'AUC_ROC' : auc_roc } \n",
    "        save_checkpoint(val_checkpoint)\n",
    "        \n",
    "        print(\"Saving Model with F1 score :\", F1)\n",
    "        \n",
    "        torch.save(model.state_dict(), model_save_dir + 'best_F1_model_Base_NN' + \".torch\")\n",
    "        \n",
    "    if sensitivity>best_sen_score:\n",
    "        \n",
    "        best_sen_score = sensitivity\n",
    "        \n",
    "        val_sensitive_checkpoint = {'model_state' : model.state_dict(), 'optimizer_state' : optimizer.state_dict(), \n",
    "                              'F1_Score' : F1, 'val_sensitivity_score' : sensitivity, 'AUC_ROC' : auc_roc } \n",
    "        save_sensitive_checkpoint(val_sensitive_checkpoint)\n",
    "        \n",
    "        print(\"Saving Sensitive Model with sensitivity :\", sensitivity)\n",
    "        \n",
    "        torch.save(model.state_dict(), model_save_dir + 'best_sensitive_model_Base_NN' + \".torch\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04856eb",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1bc8c2",
   "metadata": {},
   "source": [
    "# Test_dataset_define\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ba9d9944",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img_dir = 'E:/Tanvir Mehedi/Nodule_Classification/Data/test/'\n",
    "\n",
    "test_ds = ImageFolderCustom(\n",
    "        targ_dir = test_img_dir,\n",
    "        transform = None,\n",
    "    )\n",
    "\n",
    "test_loader = DataLoader(\n",
    "        test_ds,\n",
    "        batch_size = 1,\n",
    "        num_workers = num_workers,\n",
    "        shuffle = False,\n",
    "        drop_last = True,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed7d04d",
   "metadata": {},
   "source": [
    "# Saved_model_load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9c7adee9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(model_save_dir + 'best_model_paper.torch', map_location = device))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773fe165",
   "metadata": {},
   "source": [
    "# Perform_testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "881c5cc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6556faa7137a4a03aff58504f2806bb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ") Test Loss :  0.7841772686422885\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'all_preds_on_cpu' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11696/896999591.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[0mprecision\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtp\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtp\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[0mF1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0msensitivity\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mprecision\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msensitivity\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mprecision\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m \u001b[0mall_labels_on_cpu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos_preds_preds_on_cpu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mauc_roc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mauc_roc_calc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos_preds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\nTest Accuracy(mean): %f %%'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0macc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11696/1422320437.py\u001b[0m in \u001b[0;36mauc_roc_calc\u001b[1;34m(all_labels, pos_preds)\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mtensor\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpos_preds\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mtensor_on_cpu\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[0mall_preds_on_cpu\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor_on_cpu\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mauc_roc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_labels_on_cpu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos_preds_on_cpu\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'all_preds_on_cpu' is not defined"
     ]
    }
   ],
   "source": [
    "model.eval() \n",
    "\n",
    "test_loss =  0\n",
    "test_CM = 0\n",
    "\n",
    "all_labels = []\n",
    "all_preds = []\n",
    "pos_preds = []\n",
    "\n",
    "with torch.inference_mode():\n",
    "\n",
    "    for itera_no, test_data in tqdm(enumerate(test_loader)):\n",
    "\n",
    "        test_images, test_labels = test_data\n",
    "        test_images, test_labels = test_images.to(device), test_labels.to(device)\n",
    "        \n",
    "        all_labels.append(test_labels)\n",
    "        \n",
    "        test_pred_logits = model(test_images)\n",
    "\n",
    "        test_loss_batch = loss_criterion(test_pred_logits, test_labels)\n",
    "        test_loss += test_loss_batch.item()\n",
    "\n",
    "        test_class =  torch.argmax(torch.sigmoid(test_pred_logits), dim = 1)\n",
    "#         print(test_class.item(), test_labels.item())\n",
    "        \n",
    "        pos_preds.append(torch.sigmoid(test_pred_logits)[0][1])\n",
    "        all_preds.append(torch.sigmoid(test_pred_logits))\n",
    "        \n",
    "        test_CM+=confusion_matrix(test_labels.cpu(), test_class.cpu(), labels = [0,1]) \n",
    "\n",
    "test_loss = test_loss / len(test_loader)\n",
    "\n",
    "\n",
    "print(\") Test Loss : \", test_loss)\n",
    "\n",
    "tn= test_CM[0][0]\n",
    "tp=test_CM[1][1]\n",
    "fp=test_CM[0][1]\n",
    "fn=test_CM[1][0]\n",
    "acc=np.sum(np.diag(test_CM)/np.sum(test_CM))\n",
    "sensitivity=tp/(tp+fn)\n",
    "precision=tp/(tp+fp)\n",
    "F1 = ((2*sensitivity*precision)/(sensitivity+precision))*100\n",
    "all_labels_on_cpu, pos_preds_preds_on_cpu, auc_roc = auc_roc_calc(all_labels, pos_preds)\n",
    "\n",
    "print('\\nTest Accuracy(mean): %f %%' % (100 * acc))\n",
    "print()\n",
    "print('Confusion Matirx : ')\n",
    "print(test_CM)\n",
    "print('- Sensitivity : ',(tp/(tp+fn))*100)\n",
    "print('- Specificity : ',(tn/(tn+fp))*100)\n",
    "print('- Precision: ',(tp/(tp+fp))*100)\n",
    "print('- NPV: ',(tn/(tn+fn))*100)\n",
    "print('- F1 : ',F1)\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "12e6dffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Accuracy(mean): 94.527741 %\n",
      "\n",
      "Confusion Matirx : \n",
      "[[60860  3497]\n",
      " [   36   169]]\n",
      "- Sensitivity :  82.4390243902439\n",
      "- Specificity :  94.56624764982831\n",
      "- Precision:  4.609929078014184\n",
      "- NPV:  99.94088281660535\n",
      "- F1 :  8.731593903384137\n",
      "- AUC :  0.9427285753970706\n"
     ]
    }
   ],
   "source": [
    "tn= test_CM[0][0]\n",
    "tp=test_CM[1][1]\n",
    "fp=test_CM[0][1]\n",
    "fn=test_CM[1][0]\n",
    "acc=np.sum(np.diag(test_CM)/np.sum(test_CM))\n",
    "sensitivity=tp/(tp+fn)\n",
    "precision=tp/(tp+fp)\n",
    "F1 = ((2*sensitivity*precision)/(sensitivity+precision))*100\n",
    "all_labels_on_cpu, pos_preds_preds_on_cpu, auc_roc = auc_roc_calc(all_labels, pos_preds)\n",
    "\n",
    "print('\\nTest Accuracy(mean): %f %%' % (100 * acc))\n",
    "print()\n",
    "print('Confusion Matirx : ')\n",
    "print(test_CM)\n",
    "print('- Sensitivity : ',(tp/(tp+fn))*100)\n",
    "print('- Specificity : ',(tn/(tn+fp))*100)\n",
    "print('- Precision: ',(tp/(tp+fp))*100)\n",
    "print('- NPV: ',(tn/(tn+fn))*100)\n",
    "print('- F1 : ',F1)\n",
    "print('- AUC : ' , auc_roc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c780cd58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC_PR : 0.14048534892864237\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "precision, recall, _ = precision_recall_curve(all_labels_on_cpu, pos_preds_preds_on_cpu)\n",
    "auc_pr = average_precision_score(all_labels_on_cpu, pos_preds_preds_on_cpu)\n",
    "print('AUC_PR :', auc_pr)\n",
    "\n",
    "plt.plot(recall, precision, label='PR curve (AUC = %0.2f)' % auc_pr)\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ecc1437",
   "metadata": {},
   "source": [
    "# Plot_Auc_Roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5240577",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(all_labels_on_cpu, pos_preds_preds_on_cpu)\n",
    "\n",
    "# calculate ROC AUC score\n",
    "roc_auc = roc_auc_score(all_labels_on_cpu, all_preds_on_cpu)\n",
    "\n",
    "# plot ROC curve\n",
    "plt.plot(fpr, tpr, label='ROC curve (AUC = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Random guessing')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbfc7bf4",
   "metadata": {},
   "source": [
    "# Check_misclassified_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6c8ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval() \n",
    "\n",
    "test_loss =  0\n",
    "test_CM = 0\n",
    "\n",
    "with torch.inference_mode():\n",
    "\n",
    "    for itera_no, test_data in tqdm(enumerate(test_loader)):\n",
    "\n",
    "        test_images, test_labels = test_data\n",
    "        test_images, test_labels = test_images.to(device), test_labels.to(device)\n",
    "\n",
    "        test_pred_logits = model(test_images)\n",
    "\n",
    "        test_class =  torch.argmax(torch.sigmoid(test_pred_logits), dim = 1)\n",
    "#         print(test_class.item(), test_labels.item())\n",
    "        \n",
    "        test_CM+=confusion_matrix(test_labels.cpu(), test_class.cpu(), labels = [0,1]) \n",
    "        \n",
    "#         if test_labels == 1 :\n",
    "        if test_labels != test_class and test_labels == 0:\n",
    "            \n",
    "            print(itera_no)\n",
    "        \n",
    "print(test_CM)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15b116c",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_fn = [8,13,15,18,24,59,60,70,79,82,83,84,100,104,121,137,139,140,141]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6b109d",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_fp = [41,97,104,125,127,218,235,253,264,279,286,299,303,311,321,328,336,339,340,383,395,476,493,527,545]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
