{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "892440b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.utils import first, set_determinism\n",
    "from monai.transforms import (\n",
    "    AsDiscrete,\n",
    "    AsDiscreted,\n",
    "    AddChanneld,\n",
    "    EnsureChannelFirstd,\n",
    "    Compose,\n",
    "    CropForegroundd,\n",
    "    LoadImaged,\n",
    "    Orientationd,\n",
    "    RandCropByPosNegLabeld,\n",
    "    SaveImaged,\n",
    "    ScaleIntensityRanged,\n",
    "    RandAffined,\n",
    "    Spacingd,\n",
    "    Invertd,\n",
    "    Resized,\n",
    "    ToTensord,\n",
    "    EnsureTyped,\n",
    "    EnsureType,\n",
    "\n",
    ")\n",
    "\n",
    "# from monai.handlers.utils import from_engine\n",
    "from monai.networks.nets import UNet\n",
    "from monai.networks.layers import Norm\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.losses import DiceLoss\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.data import CacheDataset, DataLoader, Dataset, decollate_batch\n",
    "from monai.config import print_config\n",
    "from monai.apps import download_and_extract\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import tempfile\n",
    "import shutil\n",
    "import os\n",
    "import glob\n",
    "import SimpleITK as sitk\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm, trange\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "627713ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    }
   ],
   "source": [
    "# data_dir = 'E:/Tanvir Mehedi/Tanvir_codes/Data'\n",
    "data_dir = 'E:/Tanvir Mehedi/Nodule_between_5_10/' \n",
    "root_dir =  'E:/Tanvir Mehedi/Tanvir_codes/Saved_Models'\n",
    "\n",
    "# train_images = sorted(\n",
    "#     glob.glob(os.path.join(data_dir, \"nii_imagelungonly_subset0\", \"*.nii\")))\n",
    "\n",
    "# train_labels = sorted(\n",
    "#     glob.glob(os.path.join(data_dir, \"nii_spherical_nodule_mask\", \"*.nii\")))\n",
    "\n",
    "train_images = sorted(\n",
    "    glob.glob(os.path.join(data_dir, \"Only_Lung_Portion\", \"*.nii\")))\n",
    "\n",
    "train_labels = sorted(\n",
    "    glob.glob(os.path.join(data_dir, \"Spherical_Nodule_Mask\", \"*.nii\")))\n",
    "\n",
    "data_dicts = [\n",
    "    {\"image\": image_name, \"label\": label_name}\n",
    "    for image_name, label_name in zip(train_images, train_labels)\n",
    "]\n",
    "\n",
    "train_files, val_files = data_dicts[:16], data_dicts[0:]\n",
    "print(len(val_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b87952c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_determinism(seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1090ec17",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"image\", \"label\"]),\n",
    "        EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n",
    "        ScaleIntensityRanged(\n",
    "            keys=[\"image\"], a_min=-1200, a_max=600,\n",
    "            b_min=0.0, b_max=1.0, clip=True),\n",
    "        Orientationd(keys=[\"image\", \"label\"], axcodes= 'SPL'),\n",
    "        Spacingd(keys=[\"image\", \"label\"], pixdim=(\n",
    "            1., 1., 1.), mode=(\"bilinear\", \"nearest\")),\n",
    "#         Resized(keys=[\"image\"], spatial_size=[256,512,512], mode=\"trilinear\", align_corners = True),\n",
    "#         Resized(keys=[\"label\"], spatial_size=[256,512,512], mode=\"nearest\"),\n",
    "        CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\"),\n",
    "        RandCropByPosNegLabeld(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            label_key=\"label\",\n",
    "            spatial_size=(64, 64, 64),\n",
    "            pos=3,\n",
    "            neg=1,\n",
    "            num_samples=4,\n",
    "            image_key=\"image\",\n",
    "            image_threshold=0,\n",
    "        ),\n",
    "#         RandAffined(\n",
    "#             keys=['image', 'label'],\n",
    "#             mode=('bilinear', 'nearest'),\n",
    "#             prob=1.0, spatial_size=(64, 64, 64),\n",
    "#             rotate_range=(0, 0, np.pi/3),\n",
    "#             scale_range=(0.1, 0.1, 0.1)),\n",
    "        \n",
    "#         ToTensord(keys=[\"image\", \"label\"]),\n",
    "        EnsureTyped(keys=[\"image\", \"label\"]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "val_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"image\", \"label\"]),\n",
    "        EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n",
    "        ScaleIntensityRanged(\n",
    "            keys=[\"image\"], a_min=-1200, a_max=600,\n",
    "            b_min=0.0, b_max=1.0, clip=True),\n",
    "        Orientationd(keys=[\"image\", \"label\"], axcodes=\"SPL\"),\n",
    "        Spacingd(keys=[\"image\", \"label\"], pixdim=(\n",
    "            1., 1., 1.), mode=(\"bilinear\", \"nearest\")),\n",
    "#         Resized(keys=[\"image\"], spatial_size=[256,512,512], mode=\"trilinear\", align_corners = True),\n",
    "#         Resized(keys=[\"label\"], spatial_size=[256,512,512], mode=\"nearest\"),\n",
    "        CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\"),\n",
    "        \n",
    "        ToTensord(keys=[\"image\", \"label\"]),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "716ab053",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image shape: torch.Size([4, 1, 64, 64, 64]), label shape: torch.Size([4, 1, 64, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "check_ds = Dataset(data=train_files, transform=train_transforms)\n",
    "#check_ds = Dataset(data=train_files)\n",
    "check_loader = DataLoader(check_ds, batch_size=1)\n",
    "check_data = first(check_loader)\n",
    "image, label = (check_data[\"image\"], check_data[\"label\"])\n",
    "print(f\"image shape: {image.shape}, label shape: {label.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7713b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.any(label[label==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94d11d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d2385b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sli = image[0,0,32,:,:]\n",
    "plt.hist(sli)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6fe3a74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Sample: 0\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8088/3167243712.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Number of Sample:\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"check\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'image'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "a=4\n",
    "for j in range(a):\n",
    "    print(\"Number of Sample:\",j)\n",
    "    plt.figure(\"check\", (12, 6))\n",
    "    for i in range(image.shape[2]):\n",
    "        print('image', i)\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.title(\"image\")\n",
    "        plt.imshow(image[j,0,i, :, :], cmap=\"gray\")\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.title(\"label\")\n",
    "        plt.imshow(label[j,0,i, :, :],  cmap=\"gray\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a1f9b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Parameters\n",
    "batch_size = 1\n",
    "num_workers = 2\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90236fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "train_ds = Dataset(data = train_files, transform = train_transforms)\n",
    "train_loader = DataLoader(train_ds, batch_size = batch_size, shuffle = True, num_workers = num_workers)\n",
    "\n",
    "# Validation\n",
    "val_ds = Dataset(data = val_files, transform = val_transforms)\n",
    "val_loader = DataLoader(val_ds, batch_size = 1, num_workers = num_workers)\n",
    "\n",
    "# Test\n",
    "# test_ds = Dataset(data = test_files, transform = test_transforms)\n",
    "# test_loader = DataLoader(test_ds, batch_size = batch_size, num_workers = num_workers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c83d578",
   "metadata": {},
   "outputs": [],
   "source": [
    "label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f32f6a65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "27731bb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "24\n",
      "35\n",
      "49\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "\n",
    "for a,b in enumerate(train_loader) :\n",
    "    \n",
    "    img = b['image']\n",
    "    msk = b['label']\n",
    "    \n",
    "    for i in range(16):\n",
    "        \n",
    "        label = msk[i,:,:,:,:]\n",
    "    #         print(label.shape)\n",
    "\n",
    "        if torch.any(label[label==1]) :\n",
    "\n",
    "            count = count+1\n",
    "    print(count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1e0078eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "for i in range(16):\n",
    "        \n",
    "    label = msk[i,:,:,:,:]\n",
    "#         print(label.shape)\n",
    "\n",
    "    if torch.any(label[label==1]) :\n",
    "\n",
    "        count = count+1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12ef949",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.any(msk[msk==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "25d77399",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNet(\n",
    "    spatial_dims = 3,\n",
    "    in_channels = 1,\n",
    "    out_channels = 2,\n",
    "#     channels = (32, 64, 128, 256, 512),\n",
    "    channels=(16, 32, 64, 128, 256),\n",
    "    strides = (2, 2, 2, 2),\n",
    "    num_res_units = 2,\n",
    "    norm = Norm.BATCH,\n",
    ").to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67501d80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "574a740b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_function = DiceLoss(to_onehot_y = False, sigmoid = True)\n",
    "loss_function = DiceLoss(to_onehot_y=True, softmax=True)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), 0.1)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr=0.0001, max_lr=0.01,step_size_up=5,\n",
    "                                              mode=\"triangular2\", cycle_momentum = False)\n",
    "# scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size = 10, gamma=0.1)\n",
    "\n",
    "dice_metric = DiceMetric(include_background = False, reduction = \"mean\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c86eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state, filename = 'nodule_seg_3d_run_monai.pt.tar'):\n",
    "    \n",
    "    print('=> Saving Checkpoint')\n",
    "    torch.save(state, filename)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "943621f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epochs = 250\n",
    "val_interval = 2\n",
    "best_metric = -1\n",
    "best_metric_epoch = -1\n",
    "epoch_loss_values = []\n",
    "metric_values = []\n",
    "post_pred = Compose([EnsureType(), AsDiscrete(argmax=True, to_onehot=True, num_classes=2)])\n",
    "post_label = Compose([EnsureType(), AsDiscrete(to_onehot=True, num_classes=2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d09364",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(max_epochs):\n",
    "    \n",
    "    print(\"-\" * 10)\n",
    "    print(f\"epoch {epoch + 1}/{max_epochs}\")\n",
    "    \n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    step = 0\n",
    "    \n",
    "    for batch_data in train_loader:\n",
    "        step += 1\n",
    "        inputs, labels = (\n",
    "            batch_data[\"image\"].to(device),\n",
    "            batch_data[\"label\"].to(device),\n",
    "        )\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm = 2. , norm_type=2.0)\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        print(\n",
    "            f\"{step}/{len(train_ds) // train_loader.batch_size}, \"\n",
    "            f\"train_loss: {loss.item():.4f}\")\n",
    "    \n",
    "    epoch_loss /= step\n",
    "    epoch_loss_values.append(epoch_loss)\n",
    "    \n",
    "    print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\")\n",
    "\n",
    "    if (epoch + 1) % val_interval == 0:\n",
    "        \n",
    "        model.eval()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            \n",
    "            for val_data in val_loader:\n",
    "                val_inputs, val_labels = (\n",
    "                    val_data[\"image\"].to(device),\n",
    "                    val_data[\"label\"].to(device),\n",
    "                )\n",
    "# -----------\n",
    "                # compute metric for current iteration  \n",
    "#                 val_outputs = model(val_inputs)\n",
    "#                 val_outputs = torch.sigmoid(val_outputs)>0.5\n",
    "# ----------\n",
    "                roi_size = (64, 64, 64)\n",
    "                sw_batch_size = 4\n",
    "                val_outputs = sliding_window_inference(val_inputs, roi_size, sw_batch_size, model)\n",
    "                val_outputs = [post_pred(i) for i in decollate_batch(val_outputs)]\n",
    "                val_labels = [post_label(i) for i in decollate_batch(val_labels)]\n",
    "                dice_metric(y_pred = val_outputs, y = val_labels)\n",
    "                \n",
    "\n",
    "            # aggregate the final mean dice result\n",
    "            metric = dice_metric.aggregate().item()\n",
    "            # reset the status for next validation round\n",
    "            dice_metric.reset()\n",
    "\n",
    "            metric_values.append(metric)\n",
    "            if metric > best_metric:\n",
    "                best_metric = metric\n",
    "                best_metric_epoch = epoch + 1\n",
    "                \n",
    "                checkpoint = {'model_state' : model.state_dict(), 'optimizer_state' : optimizer.state_dict(), \n",
    "                              'Dice_Score' : metric } \n",
    "                save_checkpoint(checkpoint)\n",
    "                \n",
    "                torch.save(model.state_dict(), os.path.join(\n",
    "                    root_dir, \"best_metric_model.pth\"))\n",
    "                print(\"saved new best metric model\")\n",
    "            print(\n",
    "                f\"current epoch: {epoch + 1} current mean dice: {metric:.4f}\"\n",
    "                f\"\\nbest mean dice: {best_metric:.4f} \"\n",
    "                f\"at epoch: {best_metric_epoch}\"\n",
    "            )\n",
    "    scheduler.step()  # decay LR (if step_size hit)\n",
    "    curr_lr = scheduler.get_last_lr()\n",
    "    print('Current learning rate', curr_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c48ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(curr_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d2f0d717",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = 'E:/Tanvir Mehedi/Tanvir_codes/Saved_Models/best_metric_model.pth'\n",
    "model.load_state_dict(torch.load(path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3130f59e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.003050349187105894\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    for val_data in val_loader:\n",
    "        val_inputs, val_labels = (\n",
    "            val_data[\"image\"].to(device),\n",
    "            val_data[\"label\"].to(device),\n",
    "        )\n",
    "# -----------\n",
    "        # compute metric for current iteration  \n",
    "#                 val_outputs = model(val_inputs)\n",
    "#                 val_outputs = torch.sigmoid(val_outputs)>0.5\n",
    "# ----------\n",
    "        roi_size = (64, 64, 64)\n",
    "        sw_batch_size = 1\n",
    "        val_outputs = sliding_window_inference(val_inputs, roi_size, sw_batch_size, model)\n",
    "\n",
    "        val_outputs = [post_pred(i) for i in decollate_batch(val_outputs)]\n",
    "#         val_labels = [post_label(i) for i in decollate_batch(val_labels)]\n",
    "        \n",
    "        dice_metric(y_pred = val_outputs, y = val_labels)\n",
    "\n",
    "\n",
    "    # aggregate the final mean dice result\n",
    "    metric = dice_metric.aggregate().item()\n",
    "    \n",
    "    print(metric)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deadd774",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_labels[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c488e0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_outputs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d91837",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = val_labels[0].argmax(0).cpu()\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd511edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "imgs = a\n",
    "\n",
    "for i in range(len(imgs)):\n",
    "    print(\"image %d\" % i)\n",
    "#     fig,ax = plt.plot(figsize=[8,8])\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(imgs[i],cmap='gray')\n",
    "    plt.show()\n",
    "imgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e434100",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(inputs.dtype), print(labels.dtype), print(outputs.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29cfe3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_labels[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a667a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(val_labels[0][1,150,:,:].detach().cpu().numpy(), cmap = plt.cm.bone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cce87f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(torch.sigmoid(outputs[2,0,50,:,:]).detach().cpu().numpy(), cmap = plt.cm.bone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e73917",
   "metadata": {},
   "outputs": [],
   "source": [
    "import monai; monai.config.print_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09883d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"image\", \"label\"]),\n",
    "        EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n",
    "        ScaleIntensityRanged(\n",
    "            keys=[\"image\"], a_min=-1200, a_max=600,\n",
    "            b_min=0.0, b_max=1.0, clip=True),\n",
    "        Orientationd(keys=[\"image\", \"label\"], axcodes=\"SPL\"),\n",
    "        Spacingd(keys=[\"image\", \"label\"], pixdim=(\n",
    "            1., 1., 1.), mode=(\"bilinear\", \"nearest\")),\n",
    "        Resized(keys=[\"image\"], spatial_size=[256,512,512], mode=\"trilinear\", align_corners = True),\n",
    "        Resized(keys=[\"label\"], spatial_size=[256,512,512], mode=\"nearest\"),\n",
    "        RandCropByPosNegLabeld(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            label_key=\"label\",\n",
    "            spatial_size=(64, 64, 64),\n",
    "            pos=1,\n",
    "            neg=1,\n",
    "            num_samples=4,\n",
    "            image_key=\"image\",\n",
    "            image_threshold=0,\n",
    "        ),\n",
    "        ToTensord(keys=[\"image\", \"label\"]),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57b1638",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ds = Dataset(data = val_files, transform = val_transforms)\n",
    "val_loader = DataLoader(val_ds, batch_size = 1, num_workers = num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad92002",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "        \n",
    "with torch.no_grad():\n",
    "\n",
    "    for val_data in val_loader:\n",
    "        val_inputs, val_labels = (\n",
    "            val_data[\"image\"].to(device),\n",
    "            val_data[\"label\"].to(device),\n",
    "        )\n",
    "        val_outputs = model(val_inputs)\n",
    "        loss = loss_function(val_outputs, val_labels)\n",
    "        print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27fcb6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = val_outputs.argmax(1).cpu()\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9e011c",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8926972c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
